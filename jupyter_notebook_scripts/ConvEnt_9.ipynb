{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvEnt_Competition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c59c902efcf74f978f030b80dfe89a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9a71dff6d6046b2bf07c1bd035fd8d3",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61dd0761a3e14a61a372517654c19f77",
              "IPY_MODEL_f9b3de018ff5490a82984d4d92747511"
            ]
          }
        },
        "f9a71dff6d6046b2bf07c1bd035fd8d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61dd0761a3e14a61a372517654c19f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_78af568fb59c4be69cba4cf4cd9f6ee3",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 688,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 688,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7148c6d12e7b40d98d6f71f1c3d60dec"
          }
        },
        "f9b3de018ff5490a82984d4d92747511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_472fe1b2a80241a3a2ab1edb171f6529",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 688/688 [00:31&lt;00:00, 22.2B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ff848ae9ce5b486890d80e1efcc7e5f4"
          }
        },
        "78af568fb59c4be69cba4cf4cd9f6ee3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7148c6d12e7b40d98d6f71f1c3d60dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "472fe1b2a80241a3a2ab1edb171f6529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ff848ae9ce5b486890d80e1efcc7e5f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fc872452211c46699d5b7ac13e49f8b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bf06bfe722e1431fa17f5ce2db33c20e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3065ceb10e3c4a1dad1b2dd4bec80751",
              "IPY_MODEL_28380f153fcb4659951347a1e11f8f68"
            ]
          }
        },
        "bf06bfe722e1431fa17f5ce2db33c20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3065ceb10e3c4a1dad1b2dd4bec80751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6b8828bc3c8444bc9b3fa509c85c9b92",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df1a52f838ba45b19ae723210e3a262c"
          }
        },
        "28380f153fcb4659951347a1e11f8f68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_88503f2bec6b4dfd9182390ccb7b7f6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 891kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd286c46ec0c48bc84e441d25b5a0726"
          }
        },
        "6b8828bc3c8444bc9b3fa509c85c9b92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df1a52f838ba45b19ae723210e3a262c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88503f2bec6b4dfd9182390ccb7b7f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd286c46ec0c48bc84e441d25b5a0726": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bef60c3589784c3f82c9f0902c7a9506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a3d8120af7e142d3b286f60ccc30b777",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ee36b29790af4a2f8b1377e42e974773",
              "IPY_MODEL_fe437e35ec2340ffbe7c7d3828a8db06"
            ]
          }
        },
        "a3d8120af7e142d3b286f60ccc30b777": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee36b29790af4a2f8b1377e42e974773": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ba84007a2b143d0bcb1c4367b3c22fe",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bfc22b6a92534794b42e27ea79bbdc98"
          }
        },
        "fe437e35ec2340ffbe7c7d3828a8db06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_368a6b614cb640529d771c2cc667121f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:29&lt;00:00, 15.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bdb08fae839b4f32bc6f84d8fb9d64fa"
          }
        },
        "5ba84007a2b143d0bcb1c4367b3c22fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bfc22b6a92534794b42e27ea79bbdc98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "368a6b614cb640529d771c2cc667121f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bdb08fae839b4f32bc6f84d8fb9d64fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2875c59fa5ea4bb4ad8c06add16e5e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff2f03b5e54e43d690b3ebf466a7ccce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_356cfec8d9e0416bbb8184fd0ba413b4",
              "IPY_MODEL_67698db95869470b8531ed37dee2e03e"
            ]
          }
        },
        "ff2f03b5e54e43d690b3ebf466a7ccce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "356cfec8d9e0416bbb8184fd0ba413b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e0c2ccab19724b619a26998cee506de4",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1355863,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1355863,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad4ab79b56d94f8ea60c1ef6a0e38eb6"
          }
        },
        "67698db95869470b8531ed37dee2e03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_daa9bc1dc13a418b81ec6581aba5e1ec",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.36M/1.36M [00:08&lt;00:00, 162kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ed98b8929b741c2b68c522e3ce3ccf9"
          }
        },
        "e0c2ccab19724b619a26998cee506de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad4ab79b56d94f8ea60c1ef6a0e38eb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "daa9bc1dc13a418b81ec6581aba5e1ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ed98b8929b741c2b68c522e3ce3ccf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "75105f0b48f740b4bf318633ce33a44e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf6b3c5d675046289c06c226337597a6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4a8dbe8185d44fdf95a0a20e63a42283",
              "IPY_MODEL_52a5da576dc8405092a68121e0d2a629"
            ]
          }
        },
        "cf6b3c5d675046289c06c226337597a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4a8dbe8185d44fdf95a0a20e63a42283": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8db29add4cb4a6ebde1925dd23eb9eb",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1425744429,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1425744429,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c9111d54cc174b54a0396d79d8c16ee5"
          }
        },
        "52a5da576dc8405092a68121e0d2a629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa6e2fcb83744853bc0cd7f3b9f651a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.43G/1.43G [00:18&lt;00:00, 75.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f07e4d336fc14c38b1a31058352daa3a"
          }
        },
        "f8db29add4cb4a6ebde1925dd23eb9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c9111d54cc174b54a0396d79d8c16ee5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa6e2fcb83744853bc0cd7f3b9f651a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f07e4d336fc14c38b1a31058352daa3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGFeVpzY9D8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c6e529b-5906-44b3-85d3-39d9dea9c9c1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1O3MtrV96uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "866424ae-7672-4280-9789-eb90315e25cf"
      },
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  print(\"Using the GPU!\")\n",
        "  torch.backends.cudnn.enabled = True\n",
        "  torch.backends.cudnn.benchmark = True\n",
        "else:\n",
        "  print(\"WARNING: Could not find GPU! Using CPU only. If you want to enable GPU, please to go Edit > Notebook Settings > Hardware Accelerator and select GPU.\")\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using the GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CpNKTZ27QjN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca532f2-cf56-4da3-dd5e-78269823d629"
      },
      "source": [
        "try:\n",
        "  from transformers import AutoTokenizer, AutoModel\n",
        "except:\n",
        "  !pip install transformers\n",
        "  from transformers import AutoTokenizer, AutoModel\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import json\n",
        "from glob import glob\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "import pandas as pd\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from tqdm import tqdm\n",
        "from transformers import AutoTokenizer, AutoModel, AdamW, get_linear_schedule_with_warmup\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "import json\n",
        "\n",
        "path = '/content/drive/Shareddrives/EECS595-Fall2020/Final_Project_Common/Conversational_Entailment'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 14.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 50.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=504053e935fc523fc05e1025a5adb7ee3394a1ec0db77ece9dcbfa8565e4df10\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPiN4Gfr9UqN"
      },
      "source": [
        "# Conversational Entailment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvK-21mgBUT7"
      },
      "source": [
        "There are 520 samples in this dataset.\n",
        "\n",
        "The binary label indicates if this story is plausible. If lable is 0, this story is implausible. In this case, the breakpoint will not be -1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96vHfNI2EooZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3cde471-15f3-43af-c41c-c08913f47aa9"
      },
      "source": [
        "max_length = 0\n",
        "\n",
        "with open(path + '/dev_set.json') as json_file:\n",
        "  dataset = json.load(json_file)\n",
        "\n",
        "dialogue_acts_ds = dict()\n",
        "with open(path + \"/act_tag.json\") as tag_file:\n",
        "  dialogue_acts = json.load(tag_file)\n",
        "\n",
        "for meta in dialogue_acts:\n",
        "  dialogue_acts_ds[meta[\"id\"]] = meta[\"items\"]\n",
        "\n",
        "dataset[:3]\n",
        "item = dataset[1]['items'][0]\n",
        "item = item['items'][0]\n",
        "\"Speaker\" + item['speaker'] + \": \" + item['text']\n",
        "\n",
        "dataset_df = pd.DataFrame(columns=['sentence1', 'sentence2', 'label', 'idx'])\n",
        "for j_obj in dataset:\n",
        "  meta_data = dialogue_acts_ds[j_obj[\"id\"]]\n",
        "\n",
        "  # sentence1 = \"[\"\n",
        "  sentence1 = \"\"\n",
        "  items = j_obj['items']\n",
        "  conv = items[0]['items']\n",
        "  for i, dl in enumerate(meta_data):\n",
        "    # for dl in items[0]['items']:\n",
        "      # sentence1 = sentence1 + \"Speaker\" + dl['speaker'] + \": \" + dl['text'] + \" \"\n",
        "    dialoge = \"Speaker\" + conv[i]['speaker'] + \": \"\n",
        "    # dialoge = \"Speaker\" + conv[i]['speaker'] + \":[ \"\n",
        "    tags = dl[\"act_tag\"]\n",
        "    text = dl[\"text\"]\n",
        "    \n",
        "    for j, tg in enumerate(tags):\n",
        "      #  dialoge = dialoge + \" [ \" + text[j] + \", \" + tg + \" ]\"\n",
        "       dialoge = dialoge + text[j][:-1] + \"{T: \" + tg + \"}\" + \"/ \"\n",
        "      #  if j != len(tags) -1:\n",
        "      #    dialoge = dialoge + \", \"\n",
        "    \n",
        "    # dialoge = dialoge + \" ]}\"\n",
        "    # dialoge = dialoge + \" ]\"\n",
        "    # if i != len(meta_data) -1:\n",
        "    #   dialoge = dialoge + \", \"\n",
        "    sentence1 = sentence1 + dialoge\n",
        "\n",
        "  # sentence1 = sentence1 + \" ]\"\n",
        "  # print(\"sen1: \", sentence1)\n",
        "  row = pd.DataFrame(\n",
        "    {\"sentence1\": [sentence1],\n",
        "      \"sentence2\": [items[-1]['text']],\n",
        "      \"label\": int(j_obj['entailment']),\n",
        "      \"idx\": [j_obj['id']]})\n",
        "  dataset_df = pd.concat([dataset_df, row])\n",
        "  if len(sentence1.strip().split()) > max_length:\n",
        "    max_length = len(sentence1.strip().split())\n",
        "\n",
        "max_length\n",
        "\n",
        "# dataset_df.iloc[4]['sentence1']\n",
        "# dataset_df.iloc[4]['sentence2']"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "415"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9oZXwchta4I9",
        "outputId": "fa1ef09d-19e5-4dcf-fc47-f1029e061126"
      },
      "source": [
        "dataset_df_1 = dataset_df[dataset_df[\"label\"] == 1]\n",
        "dataset_df_0 = dataset_df[dataset_df[\"label\"] == 0]\n",
        "print(dataset_df_1.shape)\n",
        "print(dataset_df_0.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(282, 4)\n",
            "(238, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vRgaIabcqUw-"
      },
      "source": [
        "Split the dataset for train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBxaDcZuYG3s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a31d5a-4a87-4f42-ad75-021dfeb8abc1"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_val = train_test_split(dataset_df, test_size=0.2, random_state=42, shuffle=True)\n",
        "# df_test, df_val = train_test_split(test, test_size=0.5, random_state=1, shuffle=True)\n",
        "df_val.shape, df_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((104, 4), (416, 4))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H8y2I75Agx_W"
      },
      "source": [
        "We need to reindex the dataframes and save them!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgP21Y7Pgjlm"
      },
      "source": [
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)\n",
        "# df_train\n",
        "# df_test = df_test.reset_index(drop=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aw1CBqrqr3DP"
      },
      "source": [
        "## Preparing the dataset and dataloader for CE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc1GQh7yEm4C"
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, data, maxlen, with_labels=True, bert_model='roberta-large-mnli'):\n",
        "\n",
        "        self.data = data  # pandas dataframe\n",
        "        #Initialize the tokenizer\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(bert_model)  \n",
        "\n",
        "        self.maxlen = maxlen\n",
        "        self.with_labels = with_labels \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        # Selecting sentence1 and sentence2 at the specified index in the data frame\n",
        "        \n",
        "        sent1 = str(self.data.iloc[index][\"sentence1\"])\n",
        "        sent2 = str(self.data.iloc[index][\"sentence2\"])\n",
        "        # if xxx == 0:\n",
        "        #   print(\"id: \", self.data.iloc[index][\"idx\"])\n",
        "        #   print(sent1, sent2)\n",
        "        #   print(self.data.iloc[index][\"label\"])\n",
        "        #   xxx = 1\n",
        "\n",
        "        # Tokenize the pair of sentences to get token ids, attention masks and token type ids\n",
        "        # encoded_pair = self.tokenizer(sent1, sent2, \n",
        "        #                               padding='max_length',  # Pad to max_length\n",
        "        #                               truncation=True,  # Truncate to max_length\n",
        "        #                               max_length=self.maxlen,  \n",
        "        #                               return_tensors='pt')  # Return torch.Tensor objects\n",
        "\n",
        "        encoded_pair = self.tokenizer.encode_plus(\n",
        "            sent1, sent2,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.maxlen,\n",
        "            # pad_to_max_length=True,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        \n",
        "        token_ids = encoded_pair['input_ids']  # tensor of token ids\n",
        "        attn_masks = encoded_pair['attention_mask'] # binary tensor with \"0\" for padded values and \"1\" for the other values\n",
        "        token_type_ids = encoded_pair['token_type_ids']  # binary tensor with \"0\" for the 1st sentence tokens & \"1\" for the 2nd sentence tokens\n",
        "\n",
        "        # return {\n",
        "        #     'ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "        #     'mask': torch.tensor(attn_masks, dtype=torch.long),\n",
        "        #     'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "        #     'targets': torch.tensor(self.data.iloc[index][\"label\"], dtype=torch.long)\n",
        "        # }\n",
        "\n",
        "        if self.with_labels:  # True if the dataset has labels\n",
        "            return {\n",
        "                'ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(attn_masks, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "                'targets': torch.tensor(self.data.iloc[index][\"label\"], dtype=torch.long)\n",
        "            } \n",
        "        else:\n",
        "            return {\n",
        "                'ids': torch.tensor(token_ids, dtype=torch.long),\n",
        "                'mask': torch.tensor(attn_masks, dtype=torch.long),\n",
        "                'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long)\n",
        "            }"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "c59c902efcf74f978f030b80dfe89a45",
            "f9a71dff6d6046b2bf07c1bd035fd8d3",
            "61dd0761a3e14a61a372517654c19f77",
            "f9b3de018ff5490a82984d4d92747511",
            "78af568fb59c4be69cba4cf4cd9f6ee3",
            "7148c6d12e7b40d98d6f71f1c3d60dec",
            "472fe1b2a80241a3a2ab1edb171f6529",
            "ff848ae9ce5b486890d80e1efcc7e5f4",
            "fc872452211c46699d5b7ac13e49f8b0",
            "bf06bfe722e1431fa17f5ce2db33c20e",
            "3065ceb10e3c4a1dad1b2dd4bec80751",
            "28380f153fcb4659951347a1e11f8f68",
            "6b8828bc3c8444bc9b3fa509c85c9b92",
            "df1a52f838ba45b19ae723210e3a262c",
            "88503f2bec6b4dfd9182390ccb7b7f6c",
            "fd286c46ec0c48bc84e441d25b5a0726",
            "bef60c3589784c3f82c9f0902c7a9506",
            "a3d8120af7e142d3b286f60ccc30b777",
            "ee36b29790af4a2f8b1377e42e974773",
            "fe437e35ec2340ffbe7c7d3828a8db06",
            "5ba84007a2b143d0bcb1c4367b3c22fe",
            "bfc22b6a92534794b42e27ea79bbdc98",
            "368a6b614cb640529d771c2cc667121f",
            "bdb08fae839b4f32bc6f84d8fb9d64fa",
            "2875c59fa5ea4bb4ad8c06add16e5e87",
            "ff2f03b5e54e43d690b3ebf466a7ccce",
            "356cfec8d9e0416bbb8184fd0ba413b4",
            "67698db95869470b8531ed37dee2e03e",
            "e0c2ccab19724b619a26998cee506de4",
            "ad4ab79b56d94f8ea60c1ef6a0e38eb6",
            "daa9bc1dc13a418b81ec6581aba5e1ec",
            "1ed98b8929b741c2b68c522e3ce3ccf9"
          ]
        },
        "id": "yz3xQUbEHyQX",
        "outputId": "e72f98af-2957-463e-f506-781c846c9842"
      },
      "source": [
        "# maxlen = 512\n",
        "maxlen = 448\n",
        "bert_model = \"roberta-large-mnli\"\n",
        "bs = 8\n",
        "# Creating instances of training and validation set\n",
        "print(\"Reading training data...\")\n",
        "train_set = CustomDataset(df_train, maxlen, bert_model)\n",
        "# print(\"data issue: \", train_set.__getitem__(20))\n",
        "print(\"Reading validation data...\")\n",
        "val_set = CustomDataset(df_val, maxlen, bert_model)\n",
        "# Creating instances of training and validation dataloaders\n",
        "train_loader = DataLoader(train_set, batch_size=bs, num_workers=0)\n",
        "# for idx, (token_ids, attn_masks, token_type_ids, label) in enumerate(train_loader):\n",
        "#   print(idx)\n",
        "val_loader = DataLoader(val_set, batch_size=bs, num_workers=0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading training data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c59c902efcf74f978f030b80dfe89a45",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=688.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fc872452211c46699d5b7ac13e49f8b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bef60c3589784c3f82c9f0902c7a9506",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2875c59fa5ea4bb4ad8c06add16e5e87",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1355863.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Reading validation data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl1LP2Mh330z"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU0t5IFOjEYH"
      },
      "source": [
        "### Create our model based on pre-trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9YXvzo-3oaI"
      },
      "source": [
        "# Creating the customized model, by adding a drop out and a dense layer on top of Roberta to get the final output for the model.\n",
        "# from\n",
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        self.l1 = AutoModel.from_pretrained(\"roberta-large-mnli\")\n",
        "        self.pre_classifier = torch.nn.Linear(1024, 1024)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(1024, 2)\n",
        "        \n",
        "        torch.nn.init.xavier_uniform_(self.pre_classifier.weight)\n",
        "        nn.init.constant_(self.pre_classifier.bias, 0)\n",
        "\n",
        "        torch.nn.init.xavier_uniform_(self.classifier.weight)\n",
        "        nn.init.constant_(self.classifier.bias, 0)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
        "        # print('op1',type(output_1),output_1.shape)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output     "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJ6zf9Yq3Tgx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "75105f0b48f740b4bf318633ce33a44e",
            "cf6b3c5d675046289c06c226337597a6",
            "4a8dbe8185d44fdf95a0a20e63a42283",
            "52a5da576dc8405092a68121e0d2a629",
            "f8db29add4cb4a6ebde1925dd23eb9eb",
            "c9111d54cc174b54a0396d79d8c16ee5",
            "aa6e2fcb83744853bc0cd7f3b9f651a9",
            "f07e4d336fc14c38b1a31058352daa3a"
          ]
        },
        "outputId": "e3b01a42-6d3d-46d5-d05c-9d5ef02f2fe8"
      },
      "source": [
        "model = RobertaClass()\n",
        "for i, para in enumerate(model.l1.parameters()):\n",
        "  if i < 261:\n",
        "    para.requires_grad = False\n",
        "# from transformers import RobertaForSequenceClassification\n",
        "# model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=2, output_attentions = False, output_hidden_states = False)\n",
        "\n",
        "model.to(device)\n",
        "end = 1\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75105f0b48f740b4bf318633ce33a44e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1425744429.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JaXjoEdrfpLH"
      },
      "source": [
        "### Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NDbpLXkt1zUn"
      },
      "source": [
        "epochs = 10\n",
        "# Creating the loss function and optimizer\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-5)\n",
        "lr = 2e-5\n",
        "# set up optimizer and scheduler\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr, weight_decay=1e-2)\n",
        "# set up scheduler\n",
        "total_steps = len(train_loader) * epochs\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps = 0, num_training_steps = total_steps)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wIw4n8Drl_M0"
      },
      "source": [
        "# model evaluation\n",
        "def calcuate_accuracy(preds, targets):\n",
        "    n_correct = (preds==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKTUqGJsl44E"
      },
      "source": [
        "### Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qtYiha_743j"
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1qQevksasi3"
      },
      "source": [
        "import random\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "def set_seed(seed_val):\n",
        "  # seed_val = 42\n",
        "  random.seed(seed_val)\n",
        "  np.random.seed(seed_val)\n",
        "  torch.manual_seed(seed_val)\n",
        "  torch.cuda.manual_seed_all(seed_val)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1yCmt5vlnaD"
      },
      "source": [
        "### Training loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vGsofANS-gW"
      },
      "source": [
        "#### Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHxW2UlCCER0",
        "outputId": "c7504915-258d-4024-ac7e-06a389a4f9a9"
      },
      "source": [
        "set_seed(42)\n",
        "# Store the average loss after each epoch so we can plot them.\n",
        "loss_values = []\n",
        "\n",
        "best_val_loss = np.Inf\n",
        "best_val_acc = 0.0\n",
        "best_val_ep = 1\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 10 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_loader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        b_input_ids = batch['ids'].to(device)\n",
        "        b_input_mask = batch['mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        b_labels = batch['targets'].to(device)\n",
        "\n",
        "        \n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # This will return the loss (rather than the model output) because we\n",
        "        # have provided the `labels`.\n",
        "        \n",
        "        outputs = model(b_input_ids, b_input_mask, token_type_ids)\n",
        "        # print(outputs.shape)\n",
        "        loss = loss_fn(outputs, b_labels)\n",
        "\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_loader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    # eval_loss, eval_accuracy = 0, 0\n",
        "    # nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    n_correct = 0; total = 0; tr_loss=0; nb_tr_steps=0; nb_tr_examples=0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    with torch.no_grad(): \n",
        "        for _, batch in enumerate(val_loader): \n",
        "            \n",
        "            b_input_ids = batch['ids'].to(device)\n",
        "            b_input_mask = batch['mask'].to(device)\n",
        "            token_type_ids = batch['token_type_ids'].to(device)\n",
        "            b_labels = batch['targets'].to(device)\n",
        "            \n",
        "            outputs = model(b_input_ids, b_input_mask, token_type_ids)\n",
        "            loss = loss_fn(outputs, b_labels)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += calcuate_accuracy(big_idx, b_labels)\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples+=b_labels.size(0)\n",
        "            \n",
        "            # if _%5000==0:\n",
        "            #     loss_step = tr_loss/nb_tr_steps\n",
        "            #     accu_step = (n_correct*100)/nb_tr_examples\n",
        "            #     print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "            #     print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "    val_loss = tr_loss/nb_tr_steps\n",
        "    val_acc = (n_correct*100)/nb_tr_examples\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {}, loss: {}\".format(val_acc, val_loss))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "    if val_acc > best_val_acc:\n",
        "      print(\"Best validation loss improved from {} to {}\".format(best_val_loss, val_loss))\n",
        "      best_val_loss = val_loss\n",
        "      model_copy = copy.deepcopy(model)  # save a copy of the model\n",
        "      best_val_acc = val_acc\n",
        "      best_val_ep = epoch_i\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.70\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 74.03846153846153, loss: 0.5289399853119483\n",
            "  Validation took: 0:00:05\n",
            "Best validation loss improved from inf to 0.5289399853119483\n",
            "\n",
            "======== Epoch 2 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.63\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 75.96153846153847, loss: 0.5408253016380163\n",
            "  Validation took: 0:00:05\n",
            "Best validation loss improved from 0.5289399853119483 to 0.5408253016380163\n",
            "\n",
            "======== Epoch 3 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.55\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 76.92307692307692, loss: 0.5695321708917618\n",
            "  Validation took: 0:00:05\n",
            "Best validation loss improved from 0.5408253016380163 to 0.5695321708917618\n",
            "\n",
            "======== Epoch 4 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.46\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 78.84615384615384, loss: 0.6247025665182334\n",
            "  Validation took: 0:00:05\n",
            "Best validation loss improved from 0.5695321708917618 to 0.6247025665182334\n",
            "\n",
            "======== Epoch 5 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.43\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 78.84615384615384, loss: 0.6519545849699241\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 6 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.38\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 79.8076923076923, loss: 0.5875824771534938\n",
            "  Validation took: 0:00:05\n",
            "Best validation loss improved from 0.6247025665182334 to 0.5875824771534938\n",
            "\n",
            "======== Epoch 7 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.35\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 79.8076923076923, loss: 0.6371652322033277\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 8 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.32\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 79.8076923076923, loss: 0.745650751516223\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 9 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 79.8076923076923, loss: 0.7074749966940055\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "======== Epoch 10 / 10 ========\n",
            "Training...\n",
            "  Batch    10  of     52.    Elapsed: 0:00:07.\n",
            "  Batch    20  of     52.    Elapsed: 0:00:13.\n",
            "  Batch    30  of     52.    Elapsed: 0:00:20.\n",
            "  Batch    40  of     52.    Elapsed: 0:00:26.\n",
            "  Batch    50  of     52.    Elapsed: 0:00:33.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:00:34\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 79.8076923076923, loss: 0.7680215934792963\n",
            "  Validation took: 0:00:05\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_ZHL3MIw9eJ",
        "outputId": "6b8aeb45-853b-42bd-da0f-584c8235ff8e"
      },
      "source": [
        "print(\"Creation of the results' folder...\")\n",
        "!mkdir models"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the results' folder...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xiye7sA7w-Oy",
        "outputId": "32b9e1e7-d90f-40ca-d958-72d73d0800f0"
      },
      "source": [
        "# Saving the model\n",
        "path_to_model='models/{}_lr_{}_val_acc_{}_ep_{}_bs_{}.pt'.format(bert_model, lr, round(best_val_acc, 5), best_val_ep, bs)\n",
        "torch.save(model_copy.state_dict(), path_to_model)\n",
        "print(\"The model has been saved in {}\".format(path_to_model))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has been saved in models/roberta-large-mnli_lr_2e-05_val_acc_79.80769_ep_5_bs_8.pt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLsLvl9Yz5sk"
      },
      "source": [
        "### Test Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSHkN1koFmeQ"
      },
      "source": [
        "#### Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk5AFLMFFlKa",
        "outputId": "2b5646d7-89fe-418b-f3ca-ff149e4a9873"
      },
      "source": [
        "test_max_length = 0\n",
        "\n",
        "with open(path + '/test_set_unlabeled.json') as json_file:\n",
        "  test_dataset = json.load(json_file)\n",
        "\n",
        "dialogue_acts_ds = dict()\n",
        "with open(path + \"/act_tag_test.json\") as tag_file:\n",
        "  test_dialogue_acts = json.load(tag_file)\n",
        "\n",
        "for meta in test_dialogue_acts:\n",
        "  dialogue_acts_ds[meta[\"id\"]] = meta[\"items\"]\n",
        "\n",
        "test_dataset_df = pd.DataFrame(columns=['sentence1', 'sentence2', 'idx'])\n",
        "for j_obj in test_dataset:\n",
        "  meta_data = dialogue_acts_ds[j_obj[\"id\"]]\n",
        "\n",
        "  # sentence1 = \"[\"\n",
        "  sentence1 = \"\"\n",
        "  items = j_obj['items']\n",
        "  conv = items[0]['items']\n",
        "  for i, dl in enumerate(meta_data):\n",
        "    # for dl in items[0]['items']:\n",
        "      # sentence1 = sentence1 + \"Speaker\" + dl['speaker'] + \": \" + dl['text'] + \" \"\n",
        "    dialoge = \"Speaker\" + conv[i]['speaker'] + \": \"\n",
        "    # dialoge = \"Speaker\" + conv[i]['speaker'] + \":[ \"\n",
        "    tags = dl[\"act_tag\"]\n",
        "    text = dl[\"text\"]\n",
        "    \n",
        "    for j, tg in enumerate(tags):\n",
        "      #  dialoge = dialoge + \" [ \" + text[j] + \", \" + tg + \" ]\"\n",
        "       dialoge = dialoge + text[j][:-1] + \"{T: \" + tg + \"}\" + \"/ \"\n",
        "      #  if j != len(tags) -1:\n",
        "      #    dialoge = dialoge + \", \"\n",
        "    \n",
        "    # dialoge = dialoge + \" ]}\"\n",
        "    # dialoge = dialoge + \" ]\"\n",
        "    # if i != len(meta_data) -1:\n",
        "    #   dialoge = dialoge + \", \"\n",
        "    sentence1 = sentence1 + dialoge\n",
        "\n",
        "  # sentence1 = sentence1 + \" ]\"\n",
        "  # print(\"sen1: \", sentence1)\n",
        "  row = pd.DataFrame(\n",
        "    {\"sentence1\": [sentence1],\n",
        "      \"sentence2\": [items[-1]['text']],\n",
        "      \"idx\": [j_obj['id']]})\n",
        "  test_dataset_df = pd.concat([test_dataset_df, row])\n",
        "  if len(sentence1.strip().split()) > test_max_length:\n",
        "    test_max_length = len(sentence1.strip().split())\n",
        "test_max_length"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "361"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FLzHgm-ZR4pM",
        "outputId": "ac793335-b901-48d3-9aca-79c98801058b"
      },
      "source": [
        "test_dataset_df = test_dataset_df.reset_index(drop=True)\n",
        "test_dataset_df.head(5)\n",
        "# test_dataset_df.iloc[17][\"sentence1\"]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SpeakerB: {F Um, } actually have been to the m...</td>\n",
              "      <td>SpeakerB thought Misery was very suspenful.</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SpeakerA: Yeah,  {T: b}/ {C but } [ [ what, + ...</td>\n",
              "      <td>SpeakerB thinks that the first step is finding...</td>\n",
              "      <td>713</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SpeakerA: [ That's, + {F uh, } that's, ] {F uh...</td>\n",
              "      <td>SpeakerA believes drugs are a big influence on...</td>\n",
              "      <td>481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SpeakerB: Yeah,  {T: b}/ [ I, + I, ] - {T: %}/...</td>\n",
              "      <td>SpeakerB believes racial issues must be dealt ...</td>\n",
              "      <td>299</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SpeakerA: I hear this movie F X part two comin...</td>\n",
              "      <td>SpeakerA liked the movie FX</td>\n",
              "      <td>258</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           sentence1  ...  idx\n",
              "0  SpeakerB: {F Um, } actually have been to the m...  ...  117\n",
              "1  SpeakerA: Yeah,  {T: b}/ {C but } [ [ what, + ...  ...  713\n",
              "2  SpeakerA: [ That's, + {F uh, } that's, ] {F uh...  ...  481\n",
              "3  SpeakerB: Yeah,  {T: b}/ [ I, + I, ] - {T: %}/...  ...  299\n",
              "4  SpeakerA: I hear this movie F X part two comin...  ...  258\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2hy666J8aMEN"
      },
      "source": [
        "Cathy Smith, Richard Simmons, and Jane Fonda workouts are oldies"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1cnlm8dpHDJ0",
        "outputId": "d88e52a7-eff9-48c6-df03-d57283e5aac8"
      },
      "source": [
        "# maxlen = test_max_length\n",
        "maxlen = 448\n",
        "bert_model = \"roberta-large-mnli\"\n",
        "batch_size = 64\n",
        "# Creating instances of test set\n",
        "print(\"Reading test data...\")\n",
        "test_set = CustomDataset(test_dataset_df, maxlen, with_labels=False, bert_model=bert_model)\n",
        "test_loader = DataLoader(test_set, batch_size=batch_size, num_workers=0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading test data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k4Nk6AoH6gT"
      },
      "source": [
        "def test_prediction(model, device, dataloader, result_file=\"\"):\n",
        "  probs_all = []\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for _, batch in enumerate(test_loader):\n",
        "        seq = batch['ids'].to(device)\n",
        "        attn_masks = batch['mask'].to(device)\n",
        "        token_type_ids = batch['token_type_ids'].to(device)\n",
        "        # seq, attn_masks, token_type_ids = seq.to(device), attn_masks.to(device), token_type_ids.to(device)\n",
        "        logits = model(seq, attn_masks, token_type_ids)\n",
        "        _, probs = torch.max(logits.data, dim=1)\n",
        "        probs_all += probs.tolist()\n",
        "  return probs_all"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVkbTpZEdMdN",
        "outputId": "6fdc6e15-2141-444a-de72-6617054abb6e"
      },
      "source": [
        "print(\"Creation of the results' folder...\")\n",
        "!mkdir results"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creation of the results' folder...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBsufV5vz847",
        "outputId": "9292eeb3-3e50-4d3d-8254-36dbf60fcba7"
      },
      "source": [
        "# path_to_model = '/content/models/roberta-large-mnli_lr_2e-05_val_acc_79.80769_ep_7_bs_8.pt' \n",
        "# path_to_model = '/content/models/roberta-large-mnli_lr_2e-05_val_acc_80.76923_ep_8_bs_8.pt' \n",
        "# path_to_model = '/content/models/...'  # You can add here your trained model\n",
        "\n",
        "# path_to_output_file = 'results/output.txt'\n",
        "\n",
        "\n",
        "# saved_model = RobertaClass()\n",
        "# if torch.cuda.device_count() > 1:  # if multiple GPUs\n",
        "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
        "#     saved_model = nn.DataParallel(saved_model)\n",
        "\n",
        "# print()\n",
        "# print(\"Loading the weights of the model...\")\n",
        "# saved_model.load_state_dict(torch.load(path_to_model))\n",
        "# saved_model.to(device)\n",
        "\n",
        "print(\"Predicting on test data...\")\n",
        "test_preds = test_prediction(model=model_copy, device=device, dataloader=test_loader)  # set the with_labels parameter to False if your want to get predictions on a dataset without labels\n",
        "print(\"Predictions: \")\n",
        "print(test_preds)\n",
        "# len(test_preds)\n",
        "test_set_ids = test_dataset_df[\"idx\"].values.tolist()\n",
        "# print(test_set_ids)\n",
        "# print(len(test_set_ids))\n",
        "\n",
        "list_of_predictions = []\n",
        "for indx, prediction in zip(test_set_ids, test_preds):\n",
        "  d = dict()\n",
        "  d[\"id\"] = indx\n",
        "  d[\"pred\"] = prediction\n",
        "  list_of_predictions.append(d)\n",
        "\n",
        "with open('results/ConvEnt_9_preds.json', 'w') as fout:\n",
        "    json.dump(list_of_predictions , fout)\n",
        "\n",
        "\n",
        "# print(\"Predictions are available in : {}\".format(path_to_output_file))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting on test data...\n",
            "Predictions: \n",
            "[1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}